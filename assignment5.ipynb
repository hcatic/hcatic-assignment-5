{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RPeynYc4qsY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1szxxmGj4qsZ"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        batch_size = 500\n",
        "        predictions = []\n",
        "        total_samples = X.shape[0]\n",
        "\n",
        "        for start_idx in range(0, total_samples, batch_size):\n",
        "            end_idx = min(start_idx + batch_size, total_samples)\n",
        "            X_batch = X[start_idx:end_idx]\n",
        "\n",
        "            distances = self.compute_distance(X_batch, self.X_train)\n",
        "            k_indices = np.argsort(distances, axis=1)[:, :self.k]\n",
        "            k_labels = self.y_train[k_indices]\n",
        "\n",
        "            batch_predictions = np.mean(k_labels, axis=1)\n",
        "\n",
        "            predictions.extend(batch_predictions)\n",
        "\n",
        "            del distances, k_indices, k_labels, X_batch\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "          X1_squared = np.sum(X1 ** 2, axis=1).reshape(-1, 1)\n",
        "          X2_squared = np.sum(X2 ** 2, axis=1).reshape(1, -1)\n",
        "          cross_term = np.dot(X1, X2.T)\n",
        "          distances_squared = np.maximum(X1_squared - 2 * cross_term + X2_squared, 0)\n",
        "          distances = distances_squared ** 0.5\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = np.sum(np.abs(X1[:, np.newaxis] - X2), axis=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")\n",
        "        return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEFB6fne4qsZ"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    X_train = train_data.drop(columns=['Exited', 'CustomerId', 'Surname'])\n",
        "    y_train = train_data['Exited'].values\n",
        "    X_test = test_data.drop(columns=['CustomerId', 'Surname'])\n",
        "\n",
        "    combined = pd.concat([X_train, X_test], axis=0, sort=False).reset_index(drop=True)\n",
        "\n",
        "    categorical_features = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
        "    combined = pd.get_dummies(combined, columns=categorical_features, dtype=float)\n",
        "\n",
        "    all_features = combined.columns.tolist()\n",
        "\n",
        "    combined = combined.astype(float)\n",
        "\n",
        "    for feature in all_features:\n",
        "        min_value = combined[feature].min()\n",
        "        max_value = combined[feature].max()\n",
        "        if max_value - min_value > 0:\n",
        "            combined[feature] = (combined[feature] - min_value) / (max_value - min_value)\n",
        "        else:\n",
        "            combined[feature] = 0\n",
        "\n",
        "    X_train_processed = combined.iloc[:len(X_train)].values\n",
        "    X_test_processed = combined.iloc[len(X_train):].values\n",
        "\n",
        "    return X_train_processed, y_train, X_test_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4zmlW-Z4qsa"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    n_samples = X.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    classes, y_indices = np.unique(y, return_inverse=True)\n",
        "    stratified_folds = [[] for _ in range(n_splits)]\n",
        "    for cls in classes:\n",
        "        cls_indices = indices[y[indices] == cls]\n",
        "        np.random.shuffle(cls_indices)\n",
        "        cls_fold_sizes = np.array_split(cls_indices, n_splits)\n",
        "        for fold_idx in range(n_splits):\n",
        "            stratified_folds[fold_idx].extend(cls_fold_sizes[fold_idx])\n",
        "\n",
        "    auc_scores = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        val_indices = np.array(stratified_folds[fold])\n",
        "        train_indices = np.setdiff1d(indices, val_indices)\n",
        "\n",
        "        X_train_cv = X[train_indices]\n",
        "        y_train_cv = y[train_indices]\n",
        "        X_val_cv = X[val_indices]\n",
        "        y_val_cv = y[val_indices]\n",
        "\n",
        "        knn.fit(X_train_cv, y_train_cv)\n",
        "        y_val_pred = knn.predict(X_val_cv)\n",
        "\n",
        "        auc = compute_roc_auc(y_val_cv, y_val_pred)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "def get_tpr_fpr(y_true, y_scores, thresholds):\n",
        "    tpr_list = []\n",
        "    fpr_list = []\n",
        "    P = np.sum(y_true == 1)\n",
        "    N = np.sum(y_true == 0)\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        y_pred_thresh = (y_scores >= thresh).astype(int)\n",
        "        TP = np.sum((y_true == 1) & (y_pred_thresh == 1))\n",
        "        FP = np.sum((y_true == 0) & (y_pred_thresh == 1))\n",
        "        TPR = TP / P if P > 0 else 0\n",
        "        FPR = FP / N if N > 0 else 0\n",
        "        tpr_list.append(TPR)\n",
        "        fpr_list.append(FPR)\n",
        "\n",
        "    return np.array(tpr_list), np.array(fpr_list)\n",
        "\n",
        "def compute_roc_auc(y_true, y_scores):\n",
        "    thresholds = np.unique(y_scores)\n",
        "    thresholds = np.sort(thresholds)[::-1]\n",
        "    tpr_list, fpr_list = get_tpr_fpr(y_true, y_scores, thresholds)\n",
        "\n",
        "    tpr_list = np.concatenate(([0], tpr_list, [1]))\n",
        "    fpr_list = np.concatenate(([0], fpr_list, [1]))\n",
        "\n",
        "    auc = np.trapz(tpr_list, fpr_list)\n",
        "    return auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_dLiAgF4qsa",
        "outputId": "d8d20ad5-46d0-4326-afbb-8fe409718b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=3, distance_metric=euclidean, cv_score=0.8335298930882491\n",
            "k=5, distance_metric=euclidean, cv_score=0.8608676048246082\n",
            "k=7, distance_metric=euclidean, cv_score=0.8731121324091454\n",
            "k=9, distance_metric=euclidean, cv_score=0.8771936322830977\n",
            "k=3, distance_metric=manhattan, cv_score=0.8332209193992399\n",
            "k=5, distance_metric=manhattan, cv_score=0.8617254070117717\n",
            "k=7, distance_metric=manhattan, cv_score=0.8753953506554165\n",
            "k=9, distance_metric=manhattan, cv_score=0.8806790950260792\n",
            "Best hyperparameters: k=9, distance_metric=manhattan, cv_score=0.8806790950260792\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "best_k = None\n",
        "best_metric = None\n",
        "best_cv_score = 0\n",
        "\n",
        "for distance_metric in ['euclidean', 'manhattan']:\n",
        "  for k in [3, 5, 7, 9]:\n",
        "    knn = KNN(k=k, distance_metric=distance_metric)\n",
        "    cv_score = cross_validate(X, y, knn)\n",
        "    print(f\"k={k}, distance_metric={distance_metric}, cv_score={cv_score}\")\n",
        "    if cv_score > best_cv_score:\n",
        "      best_cv_score = cv_score\n",
        "      best_k = k\n",
        "      best_metric = distance_metric\n",
        "\n",
        "print(f\"Best hyperparameters: k={best_k}, distance_metric={best_metric}, cv_score={best_cv_score}\")\n",
        "\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}